###
### A complete description of a Prefect Deployment for flow 'otomoto-scraping-flow'
###
name: otomoto_scraping
description: |-
  Prefect flow that orchestrates the data scraping
  and uploading process for car manufacturers' data.

  This flow performs the following tasks:
  1. scrap_data: Task that scrapes data for car manufacturers names
  and saves it to the specified destination path.
  2. upload_directory_to_bucket: Task that uploads a directory
  to a specified Google Cloud Storage bucket.

  The flow starts by calling the scrap_data task to scrape data
  for car manufacturers from a file.
  Once the data is scraped, it is saved to the specified destination path.

  Next, the flow calls the upload_directory_to_bucket task
  to upload the scraped data directory
  to a Google Cloud Storage bucket with the specified bucket name
  and destination directory.

  This flow is designed to be used with Prefect, a dataflow automation framework.
version: 5480e0b9b1267592f36689327069a345
# The work queue that will handle this deployment's runs
work_queue_name: otomoto_scraping
work_pool_name: scraping-pool
tags: []
parameters: {}
schedule:
  cron: 0 10 * * 6
  timezone: null
  day_or: true
is_schedule_active: null
infra_overrides: {}
infrastructure:
  type: process
  env: {}
  labels: {}
  name: null
  command: null
  stream_output: true
  working_dir: null
  block_type_slug: process
  _block_type_slug: process

###
### DO NOT EDIT BELOW THIS LINE
###
flow_name: otomoto-scraping-flow
manifest_path: null
storage: null
path: /home/konradballegro
entrypoint: scraping/otomoto_scraping.py:otomoto_scraping_flow
parameter_openapi_schema:
  title: Parameters
  type: object
  properties: {}
  required: null
  definitions: null
timestamp: '2023-07-30T16:46:20.441151+00:00'
